<!DOCTYPE html>
<html lang="zh">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TTA-Bench - comprehensive benchmark for text-to-audio models</title>
    <link rel="stylesheet" href="styles.css">
    <script src="nav.js"></script>
</head>

<body>
    <header>
        <div class="logo-container">
            <img src="image/logo.png" alt="Logo" class="logo-img">
        </div>
        <nav>
        </nav>
    </header>

    <div class="main-content">
        <div class="big-logo">
            <img src="image/logo.png" alt="Logo">
        </div>
        <h1>A Comprehensive <strong id="benchmark-text">Benchmark</strong> for Evaluating<span>Text-to-Audio
                Models</span>
        </h1>

        <div class="buttons">
            <a href="#" class="btn">PAPER</a>
            <a href="https://github.com/lcc-404/TTA-Bench-tools" class="btn" target="_blank">GITHUB</a>
            <a href="https://huggingface.co/datasets/Hui519/TTA-Bench" class="btn" target="_blank">DATASET</a>
        </div>

        <div class="description">
            <p style="color: #2c3e50; font-size: 1.1em;">Text-to-Audio (TTA) generation has made rapid progress, but
                current evaluation methods remain narrow, focusing mainly on perceptual quality while overlooking
                robustness, generalization, and ethical concerns. We present <span
                    style="font-weight: bold;">TTA-Bench</span>, a comprehensive benchmark for evaluating TTA models
                across functional performance, reliability, and social responsibility. It covers seven dimensions
                including <span style="font-weight: bold;">accuracy</span>, <span
                    style="font-weight: bold;">robustness</span>, <span style="font-weight: bold;">fairness</span>, and
                <span style="font-weight: bold;">toxicity</span>, and includes 2,999 diverse prompts generated through
                automated and manual methods. We introduce a unified evaluation protocol that combines objective metrics
                with over 118,000 human annotations from both experts and general users. Ten state-of-the-art models are
                benchmarked under this framework, offering detailed insights into their strengths and limitations.
                TTA-Bench establishes a new standard for holistic and responsible evaluation of TTA systems.
            </p>

            <p>We identify 7 different aspects that are important in real-world model deployment, including:</p>
        </div>

        <ul class="features">
            <li>Accuracy</li>
            <li>Efficiency </li>
            <li>Generalization </li>
            <li>Robustness</li>
            <li>Fairness</li>
            <li>Bias</li>
            <li>Toxicity</li>
        </ul>



        <div style="text-align: center;">
            <img src="image/overview_framework.jpg" alt="Test Image">
        </div>

        <div class="stats-section">
            <div class="stats-grid">
                <div class="stat-group">
                    <h2>10 models</h2>
                    <ul>
                        <li>AudioGen</li>
                        <li>AudioLDM</li>
                        <li>AudioLDM 2</li>
                        <li>Auffusion</li>
                        <li>MAGNeT</li>
                        <li>Make-An-Audio</li>
                        <li>Make-An-Audio2</li>
                        <li>Stable-Audio</li>
                        <li>Tango</li>
                        <li>Tango2</li>
                    </ul>
                </div>


                <div class="stat-group">
                    <h2>16 metrics</h2>
                    <span>Subjective Metrics</span>
                    <ul>
                        <li>MOS-Complexity</li>
                        <li>MOS-Enjoyment</li>
                        <li>MOS-Quality</li>
                        <li>MOS-Alignment</li>
                        <li>MOS-Usefulness/li>
                        <li>Toxic</li>
                    </ul>
                    <span>Objective Metrics</span>
                    <ul>
                        <li>AES Score (4-dim)</li>
                        <li>CLAP Score</li>
                        <li>Real-Time Factor</li>
                        <li>Robustness Score</li>
                        <li>Fairness Score</li>
                        <li>Mean Absolute Deviation</li>
                        <li>Toxic Rate</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</body>

</html>